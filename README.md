This classifier was developed as part of a larger, collaborative emotion-recognition project. The original dataset had 7 emotions, 
which I reclassified into 3 categories (positive, neutral, negative), and then trained a classification model on.

The audio is converted into MFCC data, which is then fed into a convolutional neural network for classification. 

In this repository, I have included the training script along with a pretrained model.

Pretrained Model Training Accuracy Curve:
![v0_accuracy](https://github.com/yazh-sax/Audio-Emotion-Classification/assets/61364849/321e0bfb-c331-48e7-b48b-be3675e43a77)


Pretrained Model Training Loss Curve:
![v0_loss](https://github.com/yazh-sax/Audio-Emotion-Classification/assets/61364849/86b15cff-e970-468d-bcc3-ab51df47d129)
