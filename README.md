This classifier was developed as part of a larger, collaborative emotion-recognition project. The original dataset had 7 emotions, 
which I reclassified into 3 categories (positive, neutral, negative), and then trained a classification model on.

The audio is converted into MFCC data, which is then fed into a convolutional neural network for classification. 

In this repository, I have provided a pretrained model, along with its accuracy and loss curves during training:
![v0_accuracy](https://github.com/yazh-sax/Audio-Emotion-Classification/assets/61364849/321e0bfb-c331-48e7-b48b-be3675e43a77)

![v0_loss](https://github.com/yazh-sax/Audio-Emotion-Classification/assets/61364849/86b15cff-e970-468d-bcc3-ab51df47d129)
